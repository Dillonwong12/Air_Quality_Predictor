{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co_gt</th>\n",
       "      <th>s1_co</th>\n",
       "      <th>nhmc_gt</th>\n",
       "      <th>c6h6_gt</th>\n",
       "      <th>s2_nhmc</th>\n",
       "      <th>nox_gt</th>\n",
       "      <th>s3_nox</th>\n",
       "      <th>no2_gt</th>\n",
       "      <th>s4_no2</th>\n",
       "      <th>s5_o3</th>\n",
       "      <th>temp</th>\n",
       "      <th>rh</th>\n",
       "      <th>ah</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.396825</td>\n",
       "      <td>0.639299</td>\n",
       "      <td>0.220587</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.529215</td>\n",
       "      <td>0.190920</td>\n",
       "      <td>0.5688</td>\n",
       "      <td>0.438735</td>\n",
       "      <td>0.578780</td>\n",
       "      <td>0.504261</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.287139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.301587</td>\n",
       "      <td>0.576568</td>\n",
       "      <td>0.174091</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.453255</td>\n",
       "      <td>0.117579</td>\n",
       "      <td>0.6632</td>\n",
       "      <td>0.355731</td>\n",
       "      <td>0.508223</td>\n",
       "      <td>0.355890</td>\n",
       "      <td>0.326882</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.270955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.678044</td>\n",
       "      <td>0.144726</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.439900</td>\n",
       "      <td>0.150175</td>\n",
       "      <td>0.6360</td>\n",
       "      <td>0.442688</td>\n",
       "      <td>0.506101</td>\n",
       "      <td>0.407018</td>\n",
       "      <td>0.296774</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.283331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.654059</td>\n",
       "      <td>0.134937</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.447412</td>\n",
       "      <td>0.197905</td>\n",
       "      <td>0.5976</td>\n",
       "      <td>0.474308</td>\n",
       "      <td>0.521485</td>\n",
       "      <td>0.471679</td>\n",
       "      <td>0.277419</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.301618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.558118</td>\n",
       "      <td>0.099454</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.353923</td>\n",
       "      <td>0.150175</td>\n",
       "      <td>0.6880</td>\n",
       "      <td>0.450593</td>\n",
       "      <td>0.471618</td>\n",
       "      <td>0.425063</td>\n",
       "      <td>0.281720</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.302670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      co_gt     s1_co   nhmc_gt  c6h6_gt   s2_nhmc    nox_gt  s3_nox  \\\n",
       "0  0.396825  0.639299  0.220587     11.9  0.529215  0.190920  0.5688   \n",
       "1  0.301587  0.576568  0.174091      9.4  0.453255  0.117579  0.6632   \n",
       "2  0.333333  0.678044  0.144726      9.0  0.439900  0.150175  0.6360   \n",
       "3  0.333333  0.654059  0.134937      9.2  0.447412  0.197905  0.5976   \n",
       "4  0.238095  0.558118  0.099454      6.5  0.353923  0.150175  0.6880   \n",
       "\n",
       "     no2_gt    s4_no2     s5_o3      temp     rh        ah  \n",
       "0  0.438735  0.578780  0.504261  0.333333  0.489  0.287139  \n",
       "1  0.355731  0.508223  0.355890  0.326882  0.477  0.270955  \n",
       "2  0.442688  0.506101  0.407018  0.296774  0.540  0.283331  \n",
       "3  0.474308  0.521485  0.471679  0.277419  0.600  0.301618  \n",
       "4  0.450593  0.471618  0.425063  0.281720  0.596  0.302670  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"output.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_COLS = [\"co_gt\", \"s1_co\", \"nhmc_gt\", \"c6h6_gt\", \"s2_nhmc\", \"nox_gt\", \"s3_nox\", \"no2_gt\", \"s4_no2\", \"s5_o3\", \"temp\", \"rh\", \"ah\"]\n",
    "FEATURES = [\"co_gt\", \"s1_co\", \"nhmc_gt\", \"s2_nhmc\", \"nox_gt\", \"s3_nox\", \"no2_gt\", \"s4_no2\", \"s5_o3\", \"temp\", \"rh\", \"ah\"]\n",
    "TARGET = [\"c6h6_gt\"]\n",
    "MODELS = [\"SVM\", \"RF\"]\n",
    "K_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[FEATURES], df[TARGET], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Takes dataframes `X_train` and `y_train`. Performs hyperparameter tuning for models with GridSearchCV.\n",
    "Retrains all models with the best hyperparameter combinations, and returns a dictionary containing these trained models.\n",
    "'''\n",
    "def tune_hyperparams(X_train, y_train):\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    \n",
    "    # SVMs\n",
    "    svm_params = {\n",
    "        'C': [0.001, 0.01, 1, 100],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    }\n",
    "\n",
    "    svm_clf = GridSearchCV(\n",
    "        estimator=SVC(class_weight='balanced'),\n",
    "        param_grid=svm_params,\n",
    "        cv=K_FOLDS,\n",
    "        refit=True,\n",
    "        n_jobs=1,\n",
    "        verbose=2,\n",
    "        scoring='f1_weighted'\n",
    "    )\n",
    "\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    \n",
    "    # RF\n",
    "    rf_params = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 50, 100]\n",
    "    }\n",
    "\n",
    "    rf_clf = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(class_weight='balanced'),\n",
    "        param_grid=rf_params,\n",
    "        cv=K_FOLDS,\n",
    "        refit=True,\n",
    "        n_jobs=1,\n",
    "        verbose=2,\n",
    "        scoring='f1_weighted'\n",
    "    )\n",
    "\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    \n",
    "    model_dict = {\"RF\": rf_clf}\n",
    "    \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = tune_hyperparams(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters and best scores for each of the models\n",
    "for model in MODELS:\n",
    "    print(model_dict[model].best_estimator_)\n",
    "    print(\"best_params: \", model_dict[model].best_params_)\n",
    "    print(\"best_score: \", model_dict[model].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain models on the entire training set and test on testing set\n",
    "for m in MODELS:\n",
    "    final_scores = {}\n",
    "\n",
    "    if m == '':\n",
    "        model = ()\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    score = score_fn(y_test, y_pred)\n",
    "\n",
    "    final_scores[model] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
